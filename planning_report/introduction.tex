\section{Introduction}

Localization is a crucial part of navigation systems. Automotive
systems have been able to rely on \gls{GNSS} positioning for driver assistance. 
The typical position error in \gls{GNSS} are in the
order of 10 m \cite{4770175}. This magnitude of error is acceptable when a human is operating the car.
However, a fully autonomous car must be able to localize itself so that it does not for instance spontaneously change lane, which has a width in the same magnitude as the positioning error. Additionally, the autonomous car must be able to operate in many types of environments, from cities with high-rise buildings to tunnels. Satellite positioning systems perform poorly, or not at all, in these types of environments. 

Thus, the autonomous car needs other types of sensors for localization. The types of sensors that have been used for cars are: \gls{LIDAR}, cameras, \gls{IMU}, and radio receivers. However, many of these systems requires a map of the environment, or identifiable landmarks, for the localization system to determine its relative position compared to the landmarks. For instance, if the location of a stop sign was known a priori to the car, and the car could in the vicinity of the sign determine angle and distance with a good accuracy, e.g. centimetres. However, a priori knowledge of the location of landmarks, to such a degree to render the position error of the car acceptable, is rarely available. Thus, there is an additional problem of mapping the environment.

\subsection{Goal}

This project aims at producing an algorithm that provides a solution to the localization problem of the car. The problem is restricted to perform the mapping off-line and the localization on-line. However, the mapping should be done with the same sensors used in the localization and come from normal usage of a car operated by a human.  More
specifically:
\begin{itemize}
\item Use sensor data from normal operation of vehicles, a type of crowd sourcing, to estimate positions of landmarks, i.e. create maps, suitable for localization.

\item Given a map, a vehicle should be able to locate itself in that map using the same type of sensors.
\end{itemize}
The scenario to be considered is:
\begin{enumerate}
\item Install sensors on multiple cars, which operate in a normal fashion with human drivers. 
\item Let the sensors record and store data.
\item With the recorded data create a global map off-line.
\item A car entering an area that has been mapped by previous car can
  thus localize itself in this map.
\item New cars can send new sensor measurements to update the global
  map.
\end{enumerate}
The global map refers to an unique map that is shared between
vehicles. With such a system, questions like ``When is the traffic sign
coming?'' or  ``How far is this tunnel?'' can be answered. 

The quality of a landmark are two fold: the error in the estimated position of landmark and the likelihood of detecting the landmark from sensor data. If the position of a landmark can be estimated with high accuracy from some car, but cannot be readily detected by other cars, it is questionable if that type of landmark should be used. Also, the landmark maybe only be detectable during certain conditions that may not always be true. For instance, an advertisement sign could only be detected when it is in the vicinity of the road, however the sign might be replaced after a while. Thus, the extracted landmarks should be detectable in many types of 
weathers and lighting conditions, to render the system robust.  


\subsection{SLAM}

%The problem of jointly estimating the position of the vehicle and the landmarks is referred to as the \gls{SLAM} problem \cite{DBLP:journals/corr/CadenaCCLSN0L16}. The landmark can represent any well-defined point in the world, that can be detected by sensors. The landmarks can differ depending on what type of sensor that is used. For instance, a radio transmitter can receive signals from the base station, and thus the relative distance between the transmitter and the base-station can be measured. However, the

\subsection{Radio SLAM}

\gls{GNSS} signals may not always be available. With the emergence of 5G
standard, the project would also consider to integrate radio channel
estimates of 5GHz, and the commercial LTE
band into this cooperative off-line \gls{SLAM} framework:
\begin{itemize}
\item   From a mapping perspective, angular and distance information
  from the radio channel estimates could be used as additional sensor
  of the environment, with complementary characteristics compared to
  camera and LIDAR information.
\item From a positioning perspective, radio-based positioning using
multi-antenna reception could provide accurate location information of
vehicles, especially in urban areas, which complement camera and LIDAR
based SLAM.
\end{itemize}


\subsection{Visual SLAM}

\gls{SLAM} has been greatly evolved over the year and becomes very
close to large-scale real-world applications. For the visual based
\gls{SLAM}, different camera set-ups, e.g., monocular, stereo or RGB-D
cameras, required different algorithms for estimating the motion of
the camera. In our project, we are more interested in using stereo
camera as RGB-D camera naturally does not work well in outdoor scenario
and single camera potentially will suffer from the lack of estimation
of true scale.


For stereo visual \gls{SLAM}, here we listed several modern systems
which have been extensively verified in different
benchmarks. ORB-SLAM\cite{DBLP:journals/corr/Mur-ArtalT16a} is one of the modern sparse visual \gls{SLAM}
system, it is based on keypoint feature matching and sparse bundle
adjustment for estimating the motion of camera. Stereo LSD-SLAM\cite{7353631} is
a direct method which is feature free, the tracker is directly
optimizing the photometric error of  high gradient regions in the
images. SVO\cite{7782863} is a combination of both, it firstly detects sparse
features and then uses small image patches around them to perform
direct tracking. The tracked points are then input to a sparse bundle
adjustment back-end.

Opposing to camera based \gls{SLAM}, velodyne liked Lidars are capable
of generating dense and accurate depth map with relatively long range
outdoor. It is usually based on the direct alignment of point cloud
using classical iterative closest point algorithm or its variants. On
other trend, inertial unit is also an appealing option due to its low
cost and high data rate (hundreds of Hz). It is very useful to recover
the scale drift and provide aid when camera or lidar cannot run on par
with it in the same speed. At last, there is also GPS which could
provide direct position measurement and typically works in 5-10 meters
level precision when the signal is available. Though GPS could be a
possible solution for navigation, but hardly be enough for positioning
the vehicle in the correct lane.


\subsection{Industrial and the scientific relevance}

For both scientific and industrial aspects, it is an interesting topic
to build a map consists of measurements from different types of
sensors which will help to recover from sensor failure in certain
cases during the system is running. In scientific aspect, point clouds
and boundary representations are currently dominating the landscape of
dense mapping, higher-level representations, including objects and
shapes, will play a key role in the future of \gls{SLAM} \cite{DBLP:journals/corr/CadenaCCLSN0L16}. In
industrial aspect, there are other other assumption worth to be
investigated. For instance, persistent localization in longitudinal
direction.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
